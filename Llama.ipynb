{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-22T13:04:35.933902Z","iopub.status.busy":"2024-09-22T13:04:35.933037Z","iopub.status.idle":"2024-09-22T13:04:56.952557Z","shell.execute_reply":"2024-09-22T13:04:56.951528Z","shell.execute_reply.started":"2024-09-22T13:04:35.933859Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import time\n","import torch\n","\n","def load_model(model_name):\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForCausalLM.from_pretrained(model_name)\n","    return model, tokenizer"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:04:56.954635Z","iopub.status.busy":"2024-09-22T13:04:56.954236Z","iopub.status.idle":"2024-09-22T13:04:57.170810Z","shell.execute_reply":"2024-09-22T13:04:57.169599Z","shell.execute_reply.started":"2024-09-22T13:04:56.954605Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login(token=\"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\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:04:57.172242Z","iopub.status.busy":"2024-09-22T13:04:57.171941Z","iopub.status.idle":"2024-09-22T13:04:57.176558Z","shell.execute_reply":"2024-09-22T13:04:57.175770Z","shell.execute_reply.started":"2024-09-22T13:04:57.172214Z"},"trusted":true},"outputs":[],"source":["def zero_shot_prompt(question, options):\n","    return f\"Give the answer to the given question from below options.\\nQuesion :- {question}\\nOption-1 :- {options[0]}\\nOption-2 :- {options[1]}\\nOption-3 :- {options[2]}\\nOption-4 :- {options[3]}\"\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:04:57.178875Z","iopub.status.busy":"2024-09-22T13:04:57.178582Z","iopub.status.idle":"2024-09-22T13:04:57.188900Z","shell.execute_reply":"2024-09-22T13:04:57.188062Z","shell.execute_reply.started":"2024-09-22T13:04:57.178846Z"},"trusted":true},"outputs":[],"source":["def cot_prompt(question, options):\n","    return f\"Give the answer of the given question from below options.\\nQuestion :- {question}\\n{options[0]}\\n{options[1]}\\n{options[2]}\\n{options[3]}. Think step by step.\"\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:04:57.190288Z","iopub.status.busy":"2024-09-22T13:04:57.189999Z","iopub.status.idle":"2024-09-22T13:04:57.199698Z","shell.execute_reply":"2024-09-22T13:04:57.198893Z","shell.execute_reply.started":"2024-09-22T13:04:57.190259Z"},"trusted":true},"outputs":[],"source":["def perform_inference(model, tokenizer, prompt):\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    model = model.to(device)\n","    \n","    start_time = time.time()\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)  \n","    \n","    outputs = model.generate(**inputs, max_new_tokens=120)\n","    end_time = time.time()\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True), end_time - start_time\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:04:57.201020Z","iopub.status.busy":"2024-09-22T13:04:57.200754Z","iopub.status.idle":"2024-09-22T13:05:10.682883Z","shell.execute_reply":"2024-09-22T13:05:10.682180Z","shell.execute_reply.started":"2024-09-22T13:04:57.200993Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting datasets\n","  Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/site-packages (from datasets) (17.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from datasets) (3.15.4)\n","Collecting aiohttp\n","  Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/site-packages (from datasets) (4.66.5)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/site-packages (from datasets) (0.24.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from datasets) (24.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from datasets) (6.0.2)\n","Collecting xxhash\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from datasets) (2024.6.1)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Collecting async-timeout<5.0,>=4.0\n","  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n","  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.8/446.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multiprocess, multidict, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, datasets\n","Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-3.0.0 frozenlist-1.4.1 multidict-6.1.0 multiprocess-0.70.16 xxhash-3.5.0 yarl-1.11.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Generating test split: 100%|██████████| 100/100 [00:00<00:00, 19546.57 examples/s]\n","Generating validation split: 100%|██████████| 11/11 [00:00<00:00, 6160.68 examples/s]\n","Generating dev split: 100%|██████████| 5/5 [00:00<00:00, 2394.83 examples/s]\n"]}],"source":["!pip install datasets\n","from datasets import load_dataset\n","\n","dataset = load_dataset(\"cais/mmlu\", \"college_mathematics\")\n","questions = dataset['test']['question']\n","options = dataset['test']['choices']\n","answers = dataset['test']['answer']"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:05:10.684281Z","iopub.status.busy":"2024-09-22T13:05:10.683897Z","iopub.status.idle":"2024-09-22T13:05:10.689551Z","shell.execute_reply":"2024-09-22T13:05:10.688888Z","shell.execute_reply.started":"2024-09-22T13:05:10.684251Z"},"trusted":true},"outputs":[],"source":["def evaluate_models(model,tokenizer,func):\n","    output = []\n","    time = []\n","    i=0\n","    for question, option_set in zip(questions, options):\n","        prompt = func(question, option_set)\n","        out, t = perform_inference(model, tokenizer, prompt)\n","        \n","        output.append(out)\n","        time.append(t)\n","        \n","        i+=1\n","        if i%10==0:\n","            print(i)\n","    return output, time"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:05:10.691145Z","iopub.status.busy":"2024-09-22T13:05:10.690862Z","iopub.status.idle":"2024-09-22T13:06:41.931468Z","shell.execute_reply":"2024-09-22T13:06:41.930523Z","shell.execute_reply.started":"2024-09-22T13:05:10.691101Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:202: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n","  warnings.warn(\n","Downloading shards: 100%|██████████| 4/4 [01:17<00:00, 19.47s/it]\n","Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.04it/s]\n"]}],"source":["llama_model, llama_tokenizer = load_model(\"meta-llama/Meta-Llama-3-8B-Instruct\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:06:41.933116Z","iopub.status.busy":"2024-09-22T13:06:41.932683Z","iopub.status.idle":"2024-09-22T13:33:21.389963Z","shell.execute_reply":"2024-09-22T13:33:21.388879Z","shell.execute_reply.started":"2024-09-22T13:06:41.933085Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["10\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["20\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["30\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["40\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["50\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["60\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["70\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["80\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["90\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["100\n"]}],"source":["llama_zero_output, llama_zero_time = evaluate_models(llama_model, llama_tokenizer, zero_shot_prompt)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:33:21.393391Z","iopub.status.busy":"2024-09-22T13:33:21.392968Z","iopub.status.idle":"2024-09-22T13:33:21.398416Z","shell.execute_reply":"2024-09-22T13:33:21.397478Z","shell.execute_reply.started":"2024-09-22T13:33:21.393359Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["31.98461859226227\n"]}],"source":["llama_avg_zero_time = sum(llama_zero_time)/len(llama_zero_time)\n","print(llama_avg_zero_time)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T13:33:21.399721Z","iopub.status.busy":"2024-09-22T13:33:21.399452Z","iopub.status.idle":"2024-09-22T14:04:28.943247Z","shell.execute_reply":"2024-09-22T14:04:28.942329Z","shell.execute_reply.started":"2024-09-22T13:33:21.399692Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["10\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["20\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["30\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["40\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["50\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["60\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["70\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["80\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["90\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["100\n"]}],"source":["llama_cot_output, llama_cot_time = evaluate_models(llama_model, llama_tokenizer, cot_prompt)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T14:04:28.944892Z","iopub.status.busy":"2024-09-22T14:04:28.944486Z","iopub.status.idle":"2024-09-22T14:04:28.949459Z","shell.execute_reply":"2024-09-22T14:04:28.948680Z","shell.execute_reply.started":"2024-09-22T14:04:28.944859Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["37.34625450134277\n"]}],"source":["llama_avg_cot_time = sum(llama_cot_time)/len(llama_cot_time)\n","print(llama_avg_cot_time)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T14:40:05.069253Z","iopub.status.busy":"2024-09-22T14:40:05.068544Z","iopub.status.idle":"2024-09-22T14:40:05.075826Z","shell.execute_reply":"2024-09-22T14:40:05.075160Z","shell.execute_reply.started":"2024-09-22T14:40:05.069213Z"},"trusted":true},"outputs":[],"source":["def accuracy_calculation(model_answer,answers,options):\n","    c=0\n","    for i in range(len(model_answer)):\n","        v=model_answer[i].split('\\n')\n","        for j in range(1,len(v)):\n","            if 'answer' in v[j] or 'Answer' in v[j]:\n","                w=v[j].split()\n","#                 print(v[j])\n","#                 print(answers[i])\n","#                 print(options[i])\n","                if 'Option' in v[j]:\n","                    ind=v[j].find('Option')\n","                    ans=v[j][ind+7]\n","                    if int(ans)==answers[i]:\n","                        c+=1\n","                else:\n","                    for k in range(len(options[i])):\n","                        if options[i][k] in v[j]:\n","                            if k==answers[i]:\n","                                c+=1\n","    return c/len(model_answer)\n","#                 elif w[1] in options[i]:\n","#                     ans=options[answers[i]]\n","#                     if w[1]==ans:\n","#                         c+=1\n","#                 else:\n","#                     ans=w[-1]\n","#                     if int(ans)==answers[i]:\n","#                         c+=1\n","                \n","#     return c/len(model_answer)   "]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T14:40:07.848220Z","iopub.status.busy":"2024-09-22T14:40:07.847535Z","iopub.status.idle":"2024-09-22T14:40:07.852698Z","shell.execute_reply":"2024-09-22T14:40:07.851923Z","shell.execute_reply.started":"2024-09-22T14:40:07.848184Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of Llama for Zero Shot : 0.13513513513513514\n"]}],"source":["print(\"Accuracy of Llama for Zero Shot :\",accuracy_calculation(llama_zero_output,answers,options))"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-09-22T14:47:35.934620Z","iopub.status.busy":"2024-09-22T14:47:35.933932Z","iopub.status.idle":"2024-09-22T14:47:35.939257Z","shell.execute_reply":"2024-09-22T14:47:35.938588Z","shell.execute_reply.started":"2024-09-22T14:47:35.934583Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of Llama for Chain of Thought : 0.2826086956521739\n"]}],"source":["print(\"Accuracy of Llama for Chain of Thought :\",accuracy_calculation(llama_cot_output,answers,options))"]}],"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30762,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
